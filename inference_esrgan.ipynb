{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "96f4715f",
      "metadata": {},
      "source": [
        "# ESRGAN 推理脚本 (Inference)\n",
        "\n",
        "本 Notebook 用于加载训练好的 ESRGAN 模型（如 `ESRGAN_4x_finetune_best.pth`），对低分辨率 (LR) 图像进行超分辨率重建，并与原始高分辨率 (HR) 图像进行对比。支持通过 `UPSCALE_MODE` 在 2x/4x 配置间切换。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dd5965eb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version: 2.9.0+cu130\n",
            "CUDA Available: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# 将本地的 APISR_tools 目录添加到系统路径\n",
        "apisr_tools_path = os.path.abspath('APISR_tools')\n",
        "if apisr_tools_path not in sys.path:\n",
        "    sys.path.append(apisr_tools_path)\n",
        "\n",
        "# 导入 RRDBNet 架构\n",
        "from architecture.rrdb import RRDBNet\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6a4f3110",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "推理模式: 2x, SCALE=2, NUM_BLOCK=6\n",
            "模型路径: saved_models/ESRGAN_2x_finetune_best.pth\n",
            "LR 路径: dataset/lowres_2x/original\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1. 配置参数\n",
        "# ==========================================\n",
        "\n",
        "# 推理模式: '2x' 或 '4x'\n",
        "UPSCALE_MODE = '2x'\n",
        "\n",
        "# 与训练脚本保持一致的保存前缀\n",
        "CHECKPOINT_NAME = f'ESRGAN_{UPSCALE_MODE}_finetune'\n",
        "\n",
        "# 放大倍数 (必须与训练时一致)\n",
        "SCALE = 2 if UPSCALE_MODE == '2x' else 4\n",
        "\n",
        "# RRDB block 数量（必须与训练时一致）\n",
        "# 经验映射：2x 常用 6 blocks，4x 常用 23 blocks\n",
        "AUTO_NUM_BLOCK = 6 if UPSCALE_MODE == '2x' else 23\n",
        "MANUAL_NUM_BLOCK = None  # 可手动设置为 6 或 23；None 表示使用自动映射\n",
        "NUM_BLOCK = MANUAL_NUM_BLOCK if MANUAL_NUM_BLOCK is not None else AUTO_NUM_BLOCK\n",
        "\n",
        "# 模型路径 (优先加载 best)\n",
        "MODEL_PATH = f'saved_models/{CHECKPOINT_NAME}_best.pth'\n",
        "\n",
        "# 测试图像路径\n",
        "LR_DIR = f'dataset/lowres_{UPSCALE_MODE}/original'\n",
        "HR_DIR = 'dataset/highres/original'\n",
        "OUTPUT_DIR = f'results/ESRGAN_{UPSCALE_MODE}_inference'\n",
        "\n",
        "# 设备\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"推理模式: {UPSCALE_MODE}, SCALE={SCALE}, NUM_BLOCK={NUM_BLOCK}\")\n",
        "print(f\"模型路径: {MODEL_PATH}\")\n",
        "print(f\"LR 路径: {LR_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "835a34a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正在加载模型权重: saved_models/ESRGAN_2x_finetune_best.pth\n",
            "成功加载 Epoch 31 的权重。\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RRDBNet(\n",
              "  (conv_first): Conv2d(12, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (body): Sequential(\n",
              "    (0): RRDB(\n",
              "      (rdb1): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb2): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb3): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (1): RRDB(\n",
              "      (rdb1): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb2): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb3): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (2): RRDB(\n",
              "      (rdb1): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb2): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb3): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (3): RRDB(\n",
              "      (rdb1): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb2): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb3): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (4): RRDB(\n",
              "      (rdb1): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb2): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb3): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (5): RRDB(\n",
              "      (rdb1): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb2): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (rdb3): ResidualDenseBlock(\n",
              "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv4): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv5): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv_body): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_up1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_up2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_hr): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              ")"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 2. 加载模型\n",
        "# ==========================================\n",
        "\n",
        "# 实例化生成器 (RRDBNet)\n",
        "# 注意：scale 和 num_block 必须与训练时完全一致\n",
        "model = RRDBNet(3, 3, scale=SCALE, num_block=NUM_BLOCK).to(device)\n",
        "\n",
        "# 加载权重\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(f\"未找到模型权重: {MODEL_PATH}\")\n",
        "\n",
        "print(f\"正在加载模型权重: {MODEL_PATH}\")\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
        "\n",
        "# 兼容不同格式的权重文件\n",
        "if 'params_ema' in checkpoint:\n",
        "    model.load_state_dict(checkpoint['params_ema'], strict=True)\n",
        "    print(\"成功加载 params_ema 权重。\")\n",
        "elif 'model_state_dict' in checkpoint:\n",
        "    model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
        "    print(f\"成功加载 Epoch {checkpoint.get('epoch', 'Unknown')} 的权重。\")\n",
        "else:\n",
        "    model.load_state_dict(checkpoint, strict=True)\n",
        "    print(\"成功加载纯 state_dict 权重。\")\n",
        "\n",
        "# 设置为评估模式\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "13dfe52f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. 推理与可视化函数 (分块推理防爆显存)\n",
        "# ==========================================\n",
        "\n",
        "def tensor2img(tensor):\n",
        "    \"\"\"将 PyTorch Tensor 转换为 numpy 图像 (RGB, 0-255)\"\"\"\n",
        "    img = tensor.squeeze(0).cpu().numpy()\n",
        "    img = np.transpose(img, (1, 2, 0)) # CHW -> HWC\n",
        "    img = np.clip(img * 255.0, 0, 255).astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "def infer_and_save(lr_path, hr_path=None, save_dir=None, show=True):\n",
        "    \"\"\"对单张图像进行推理，保存并可选择显示对比图\"\"\"\n",
        "    # 1. 读取 LR 图像\n",
        "    lr_img = cv2.imread(lr_path)\n",
        "    if lr_img is None:\n",
        "        print(f\"无法读取图像: {lr_path}\")\n",
        "        return None\n",
        "    lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # 2. 预处理 (转为 Tensor, 归一化到 [0, 1], 增加 Batch 维度)\n",
        "    # 对 2x RRDB(scale=2) 来说，网络内部会 pixel_unshuffle(scale=2)，\n",
        "    # 分块推理时每个块的高宽都需要能被 2 整除。这里将输入 pad 到 4 的倍数，避免块内断言报错。\n",
        "    orig_h, orig_w = lr_img.shape[:2]\n",
        "    pad_h, pad_w = 0, 0\n",
        "    lr_img_model = lr_img\n",
        "    if SCALE == 2:\n",
        "        pad_h = (4 - orig_h % 4) % 4\n",
        "        pad_w = (4 - orig_w % 4) % 4\n",
        "        if pad_h > 0 or pad_w > 0:\n",
        "            lr_img_model = cv2.copyMakeBorder(\n",
        "                lr_img, 0, pad_h, 0, pad_w, borderType=cv2.BORDER_REFLECT_101\n",
        "            )\n",
        "\n",
        "    lr_tensor = torch.from_numpy(lr_img_model.transpose(2, 0, 1)).float() / 255.0\n",
        "    lr_tensor = lr_tensor.unsqueeze(0).to(device)\n",
        "    \n",
        "    # 3. 模型推理 (使用分块推理防止 OOM)\n",
        "    with torch.no_grad():\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')): # 开启混合精度加速推理\n",
        "            # 如果图像太大，直接推理会爆显存。这里使用简单的分块策略\n",
        "            # 假设 16GB 显存，LR 图像超过 512x512 可能会有风险\n",
        "            _, _, h, w = lr_tensor.shape\n",
        "            \n",
        "            if h * w > 512 * 512:\n",
        "                # 简单的 2x2 分块推理 (如果图像更大，可以增加分块数量)\n",
        "                h_half, w_half = h // 2, w // 2\n",
        "                \n",
        "                # 预分配输出 Tensor (注意尺寸要乘以 SCALE)\n",
        "                sr_tensor = torch.zeros((1, 3, h * SCALE, w * SCALE), device=device)\n",
        "                \n",
        "                # 左上\n",
        "                sr_tensor[:, :, :h_half*SCALE, :w_half*SCALE] = model(lr_tensor[:, :, :h_half, :w_half])\n",
        "                # 右上\n",
        "                sr_tensor[:, :, :h_half*SCALE, w_half*SCALE:] = model(lr_tensor[:, :, :h_half, w_half:])\n",
        "                # 左下\n",
        "                sr_tensor[:, :, h_half*SCALE:, :w_half*SCALE] = model(lr_tensor[:, :, h_half:, :w_half])\n",
        "                # 右下\n",
        "                sr_tensor[:, :, h_half*SCALE:, w_half*SCALE:] = model(lr_tensor[:, :, h_half:, w_half:])\n",
        "            else:\n",
        "                # 图像较小，直接推理\n",
        "                sr_tensor = model(lr_tensor)\n",
        "            \n",
        "    # 4. 后处理\n",
        "    sr_img = tensor2img(sr_tensor)\n",
        "\n",
        "    # 如果做过 padding，裁掉对应的 SR 边界，恢复到原图对应尺寸\n",
        "    if pad_h > 0 or pad_w > 0:\n",
        "        sr_img = sr_img[:orig_h * SCALE, :orig_w * SCALE, :]\n",
        "    \n",
        "    # 5. 保存图像\n",
        "    if save_dir:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        filename = os.path.basename(lr_path)\n",
        "        save_path = os.path.join(save_dir, filename)\n",
        "        # OpenCV 保存需要 BGR 格式\n",
        "        cv2.imwrite(save_path, cv2.cvtColor(sr_img, cv2.COLOR_RGB2BGR))\n",
        "    \n",
        "    # 6. 可视化\n",
        "    if show:\n",
        "        if hr_path and os.path.exists(hr_path):\n",
        "            # 如果有 HR 图像，显示三张图对比\n",
        "            hr_img = cv2.imread(hr_path)\n",
        "            hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            # 为了公平对比，将 LR 图像使用双三次插值放大到相同尺寸\n",
        "            h, w, _ = hr_img.shape\n",
        "            lr_resized = cv2.resize(lr_img, (w, h), interpolation=cv2.INTER_CUBIC)\n",
        "            \n",
        "            fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "            axes[0].imshow(lr_resized)\n",
        "            axes[0].set_title('LR (Bicubic Upscaled)')\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            axes[1].imshow(sr_img)\n",
        "            axes[1].set_title('SR (ESRGAN Output)')\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "            axes[2].imshow(hr_img)\n",
        "            axes[2].set_title('HR (Ground Truth)')\n",
        "            axes[2].axis('off')\n",
        "            \n",
        "        else:\n",
        "            # 如果没有 HR 图像，只显示 LR 和 SR\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "            axes[0].imshow(lr_img)\n",
        "            axes[0].set_title('LR Input')\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            axes[1].imshow(sr_img)\n",
        "            axes[1].set_title('SR (ESRGAN Output)')\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "    return sr_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ee6bb179",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始批量推理，结果将保存至: results/ESRGAN_2x_inference\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Progress:   0%|          | 0/434 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m show_vis:\n\u001b[32m     25\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mVisualizing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43minfer_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhr_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_vis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m批量推理完成！\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36minfer_and_save\u001b[39m\u001b[34m(lr_path, hr_path, save_dir, show)\u001b[39m\n\u001b[32m     37\u001b[39m sr_tensor = torch.zeros((\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, h * SCALE, w * SCALE), device=device)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 左上\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m sr_tensor[:, :, :h_half*SCALE, :w_half*SCALE] = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mh_half\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mw_half\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 右上\u001b[39;00m\n\u001b[32m     42\u001b[39m sr_tensor[:, :, :h_half*SCALE, w_half*SCALE:] = model(lr_tensor[:, :, :h_half, w_half:])\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\.conda\\envs\\ece284fa25\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\.conda\\envs\\ece284fa25\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\lixinqi\\UCSD\\ECE285\\AWM\\APISR_tools\\architecture\\rrdb.py:177\u001b[39m, in \u001b[36mRRDBNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scale == \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m         feat = \u001b[43mpixel_unshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scale == \u001b[32m1\u001b[39m:\n\u001b[32m    179\u001b[39m         feat = pixel_unshuffle(x, scale=\u001b[32m4\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\lixinqi\\UCSD\\ECE285\\AWM\\APISR_tools\\architecture\\rrdb.py:28\u001b[39m, in \u001b[36mpixel_unshuffle\u001b[39m\u001b[34m(x, scale)\u001b[39m\n\u001b[32m     26\u001b[39m b, c, hh, hw = x.size()\n\u001b[32m     27\u001b[39m out_channel = c * (scale**\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m hh % scale == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hw % scale == \u001b[32m0\u001b[39m\n\u001b[32m     29\u001b[39m h = hh // scale\n\u001b[32m     30\u001b[39m w = hw // scale\n",
            "\u001b[31mAssertionError\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 4. 批量推理并保存\n",
        "# ==========================================\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 获取所有 LR 图像路径\n",
        "lr_paths = sorted(glob.glob(os.path.join(LR_DIR, '*.*')))\n",
        "hr_paths = sorted(glob.glob(os.path.join(HR_DIR, '*.*')))\n",
        "\n",
        "if not lr_paths:\n",
        "    print(\"未找到测试图像，请检查路径。\")\n",
        "else:\n",
        "    print(f\"开始批量推理，结果将保存至: {OUTPUT_DIR}\")\n",
        "    # 随机抽取 3 张图像进行可视化展示\n",
        "    num_samples = min(3, len(lr_paths))\n",
        "    sample_indices = random.sample(range(len(lr_paths)), num_samples)\n",
        "    \n",
        "    for idx, lr_path in enumerate(tqdm(lr_paths, desc=\"Inference Progress\")):\n",
        "        filename = os.path.basename(lr_path)\n",
        "        hr_path = os.path.join(HR_DIR, filename)\n",
        "        \n",
        "        # 只有被抽中的 3 张图片会显示可视化对比，其他的只保存\n",
        "        show_vis = (idx in sample_indices)\n",
        "        if show_vis:\n",
        "            print(f\"\\nVisualizing: {filename}\")\n",
        "            \n",
        "        infer_and_save(lr_path, hr_path=hr_path, save_dir=OUTPUT_DIR, show=show_vis)\n",
        "        \n",
        "    print(\"批量推理完成！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72908fbb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正在初始化评估指标 (首次运行会自动下载预训练权重)...\n",
            "Loading pretrained model MANIQA from C:\\Users\\admin\\.cache\\torch\\hub\\pyiqa\\ckpt_koniq10k.pt\n",
            "开始评估生成的 SR 图像...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 434/434 [16:40<00:00,  2.31s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "评估结果 (Evaluation Results):\n",
            "========================================\n",
            "Average NIQE   : 5.2683 (越低越好, Lower is better)\n",
            "Average MANIQA : 0.2639 (越高越好, Higher is better)\n",
            "Average CLIPIQA: 0.4848 (越高越好, Higher is better)\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 5. 图像质量评估 (NIQE, MANIQA, CLIPIQA)\n",
        "# ==========================================\n",
        "# 注意：运行此代码块需要安装 pyiqa 库\n",
        "# 可以通过取消注释下一行来安装：\n",
        "# !pip install pyiqa\n",
        "from tqdm import tqdm\n",
        "try:\n",
        "    import pyiqa\n",
        "except ImportError:\n",
        "    print(\"未检测到 pyiqa 库，准备退出。\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "print(\"正在初始化评估指标 (首次运行会自动下载预训练权重)...\")\n",
        "# 初始化无参考图像质量评估指标 (No-Reference IQA)\n",
        "niqe_metric = pyiqa.create_metric('niqe', device=device)\n",
        "maniqa_metric = pyiqa.create_metric('maniqa', device=device)\n",
        "clipiqa_metric = pyiqa.create_metric('clipiqa', device=device)\n",
        "\n",
        "sr_paths = sorted(glob.glob(os.path.join(OUTPUT_DIR, '*.*')))\n",
        "\n",
        "niqe_scores = []\n",
        "maniqa_scores = []\n",
        "clipiqa_scores = []\n",
        "\n",
        "print(\"开始评估生成的 SR 图像...\")\n",
        "for sr_path in tqdm(sr_paths, desc=\"Evaluating\"):\n",
        "    # pyiqa 可以直接接受图像路径进行评估\n",
        "    niqe_score = niqe_metric(sr_path).item()\n",
        "    maniqa_score = maniqa_metric(sr_path).item()\n",
        "    clipiqa_score = clipiqa_metric(sr_path).item()\n",
        "    \n",
        "    niqe_scores.append(niqe_score)\n",
        "    maniqa_scores.append(maniqa_score)\n",
        "    clipiqa_scores.append(clipiqa_score)\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"评估结果 (Evaluation Results):\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Average NIQE   : {np.mean(niqe_scores):.4f} (越低越好, Lower is better)\")\n",
        "print(f\"Average MANIQA : {np.mean(maniqa_scores):.4f} (越高越好, Higher is better)\")\n",
        "print(f\"Average CLIPIQA: {np.mean(clipiqa_scores):.4f} (越高越好, Higher is better)\")\n",
        "print(\"=\"*40)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
